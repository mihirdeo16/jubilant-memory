{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to install\n",
    "# !pip install imbalanced-learn -y\n",
    "# !pip install category_encoders -y\n",
    "# !pip install seaborn\n",
    "# !pip install -U matplotlib\n",
    "# !pip install -U scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, GroupShuffleSplit, KFold,StratifiedKFold\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv(\"Path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of the data\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning & preliminary data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the data\n",
    "print(f\"Data has rows {df.shape[0]} and columns {df.shape[1]}\")\n",
    "\n",
    "print(f\"Data duplicate values {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_counter(df):\n",
    "    # Count the null\n",
    "    null_count = pd.DataFrame() \n",
    "    null_count[\"Columns\"] = df.columns\n",
    "    null_count[\"Count\"] = df.isnull().sum().values\n",
    "    null_count[\"Percent missing\"] = df.isnull().sum().values * 100 / len(df)\n",
    "\n",
    "    null_count=null_count[null_count['Count']!=0]\n",
    "    return null_count\n",
    "\n",
    "null_counter(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary observation about the data\n",
    "+ One comparing with column name to description\n",
    "+ Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary columns\n",
    "df.drop(columns=['B', 'C'],inplace=True)\n",
    "\n",
    "# Drop the columns with Nulls\n",
    "df.drop(columns=['B', 'C'],inplace=True)\n",
    "\n",
    "# Drop the rows with null subset\n",
    "df.dropna(subset=[\"A\"],how=\"any\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(null_counter(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Information about the data types\")\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into right data type\n",
    "df[\"A\"] = df[\"A\"].astype(\"category\") # object\n",
    "df[\"A\"] = df[\"A\"].astype(\"int64\") # float64\n",
    "df[\"A\"] = df[\"A\"].astype(\"bool\")\n",
    "df[\"A\"] = df[\"A\"].astype(\"datetime64\") # timedelta[ns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data analysis\n",
    "Define target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"\" # TODO\n",
    "\n",
    "def feature_type_exc(df):\n",
    "    cat_cols, num_cols = [],[]\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col == target_col:\n",
    "            continue\n",
    "        if df[col].dtype == \"object\":\n",
    "            cat_cols.append(col)\n",
    "        else:\n",
    "            num_cols.append(col)\n",
    "    feature_cols = num_cols + cat_cols\n",
    "    return cat_cols, num_cols, feature_cols\n",
    "\n",
    "cat_cols, num_cols, feature_cols =  feature_type_exc(df)\n",
    "print(\"Target/dependent feature : \", target_col,\"\\n\")\n",
    "print(\"Numerical features : \",num_cols)\n",
    "print(\"Categorical features : \",cat_cols)\n",
    "print(\"\\nInput/independent features : \",feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target data\n",
    "print(\"Target binary distribution:\\n\",df[target_col].value_counts())\n",
    "class_0 = int(df[target_col].value_counts()[0]/len(df.index))\n",
    "class_1 = int(df[target_col].value_counts()[1]/len(df.index))\n",
    "class_weight = int(df[target_col].value_counts()[0]/df[target_col].value_counts()[1])\n",
    "\n",
    "print(f\"\\nClass weight is 1:{class_weight} and ratio between them is {class_0}:{class_1}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "+ One \n",
    "+ Two"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical features analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms to show distribution of features by outcome categories\n",
    "def plot_histogram_num(x,y):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12, 10))\n",
    "    ax1.hist(list(x[y==0]), alpha=0.5, label='Outcome=0')\n",
    "    ax1.hist(list(x[y==1]), alpha=0.5, label='Outcome=1')\n",
    "    ax1.set_title(\"Histogram of '{var_name}' by Outcome Category\".format(var_name=x.name))\n",
    "    ax1.set_xlabel(\"Value\")\n",
    "    ax1.set_ylabel(\"Frequency\")\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    ax2.boxplot(x)\n",
    "    ax2.set_title(\"Boxplot of '{var_name}' by Outcome Category\".format(var_name=x.name))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_num(df['A'].fillna(value=df['A'].mean()), df[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_by_std(df,column_name):\n",
    "    upper_limit = df[column_name].mean() + 3 * df[column_name].std()\n",
    "    lower_limit = df[column_name].mean() - 3 * df[column_name].std()\n",
    "    df_dropped = df[(df[column_name]>upper_limit) | (df[column_name]<lower_limit)]\n",
    "    print(\"Total number of data point will be dropped :\",df_dropped.shape[0])\n",
    "    df_filter_outlier = df[(df[column_name]<upper_limit) & (df[column_name]>lower_limit)]\n",
    "    return df_filter_outlier, df_dropped\n",
    "\n",
    "\n",
    "def outlier_by_iqr(df,column_name):\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5*IQR\n",
    "    upper_limit = Q3 + 1.5*IQR\n",
    "    df_dropped = df[(df[column_name]>upper_limit) | (df[column_name]<lower_limit)]\n",
    "\n",
    "    print(\"Total number of data point will be dropped :\",df_dropped.shape[0])\n",
    "\n",
    "    df_filter_outlier = df[(df[column_name]<upper_limit) & (df[column_name]>lower_limit)]\n",
    "\n",
    "    return df_filter_outlier, df_dropped\n",
    "\n",
    "def outlier_by_percentile(df,column_name,up=0.99,lw=0.01):\n",
    "    lower_limit = df[column_name].quantile(lw)\n",
    "    upper_limit = df[column_name].quantile(up)\n",
    "\n",
    "    df_dropped = df[(df[column_name]>upper_limit) | (df[column_name]<lower_limit)]\n",
    "\n",
    "    print(\"Total number of data point will be dropped :\",df_dropped.shape[0])\n",
    "    df_filter_outlier = df[(df[column_name]<upper_limit) & (df[column_name]>lower_limit)]\n",
    "\n",
    "    return df_filter_outlier, df_dropped\n",
    "# fillna(valuex_train['A'].mean()\n",
    "new_df, drop_df = outlier_by_std(df,\"A\")\n",
    "new_df, drop_df = outlier_by_iqr(df,\"A\")\n",
    "new_df, drop_df = outlier_by_percentile(df,\"A\")\n",
    "print(\"\\nValues count of dropped df :\")\n",
    "print(drop_df[target_col].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "+ One \n",
    "+ Two"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6)) \n",
    "\n",
    "sns.heatmap(x.corr(), annot=True,fmt=\".1f\",ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_corr_features = ['A', 'B']\n",
    "num_norm_features = ['A', 'B'] \n",
    "\n",
    "# To reduce bias in model training drop highly correlated features and only keep one \n",
    "df.drop(columns=['B', 'C'],inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "+ One \n",
    "+ Two"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical features analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features unique values in Cat\n",
    "for col in cat_cols:\n",
    "    uni_cat_count = df[col].nunique()\n",
    "    print (\"Feature {col_name} has {unique_cat} unique categories\". format (col_name=col, unique_cat=uni_cat_count))\n",
    "    if uni_cat_count< 20:\n",
    "        print(df[col].unique())\n",
    "print(\"\\nTotal number of rows : \",df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the encoding categories\n",
    "oht_encoder = ['A', 'B']\n",
    "o_encoder = ['A', 'B']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation about all variables:\n",
    "+ One\n",
    "+ Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data frame \n",
    "cat_cols, num_cols, feature_cols =  feature_type_exc(df)\n",
    "\n",
    "print(\"Target/dependent feature : \", target_col)\n",
    "print(\"\\nNumerical features : \",num_cols)\n",
    "print(\"\\nCategorical features : \",cat_cols)\n",
    "print(\"\\nInput/independent features : \",feature_cols)\n",
    "\n",
    "print(\"\\nOne Hot encoding features\",oht_encoder)\n",
    "print(\"\\nOrdinal encoding features\",o_encoder)\n",
    "print(\"\\n Normalize transformation features\",num_norm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.filter(items=[target_col])\n",
    "x = df.drop(target_col, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MISC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier by Analysis by IsolationForest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "iso = IsolationForest(contamination=0.1)\n",
    "\n",
    "yhat = iso.fit_predict(x)\n",
    "\n",
    "# select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "\n",
    "x, y = x[mask], y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_0 = df[df.target==0]\n",
    "df_1 = df[df.target==1]\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "if df_0.shape[0] > df_1.shape[0]:\n",
    "    df_upsampled = resample(df_1, \n",
    "                                replace=True,     # sample with replacement\n",
    "                                n_samples=df_0.shape[0],    # to match majority class\n",
    "                                random_state=123) \n",
    "    df_og = df_1\n",
    "else:\n",
    "    df_upsampled = resample(df_0, \n",
    "                                replace=True,     # sample with replacement\n",
    "                                n_samples=df_1.shape[0],    # to match majority class\n",
    "                                random_state=123) \n",
    "    df_og = df_0\n",
    "    \n",
    "df = pd.concat([df_upsampled,df_og])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data modeling and experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=80, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, auc, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_calculator(y_test,y_pred,y_prob=None):\n",
    "    print(\"\\nDifferent metric reports\\n\")\n",
    "    print(f\"\\nAccuracy classification score: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"\\nBalanced accuracy classification score: {balanced_accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"\\nPrecision score: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"\\nRecall score: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"\\nAUC score: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"\\nF1 score: {f1_score(y_test, y_pred)}\")\n",
    "    cf_matrix = confusion_matrix(y_test,y_pred)\n",
    "    sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "    if y_prob:\n",
    "        print(f\"\\nROC AUC score{roc_auc_score(y_test, y_prob[:, 1])}\")\n",
    "    print(f\"\\nClassification report: \\n {classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(pipe_obj,x_train, x_test, y_train, y_test):\n",
    "    model = pipe_obj\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    print(\"Model training is Done !\")\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_prob = model.predict_proba(x_test)\n",
    "\n",
    "    return model, y_pred, y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder, StandardScaler, Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oht_encoder = ['A', 'B']\n",
    "o_encoder = ['A', 'B']\n",
    "targe_encoder = ['A', 'B']\n",
    "\n",
    "num_features = ['A', 'B'] #num_cols\n",
    "num_norm_features = ['A', 'B'] \n",
    "num_corr_features = ['A', 'B']\n",
    "\n",
    "numerical_transformer = Pipeline(\n",
    "    step = [\n",
    "        (\"imputer\",SimpleImputer(strategy=\"mean\"))\n",
    "        (\"scaler\",StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer_oht = Pipeline(\n",
    "    step = [\n",
    "        (\"oht_encoder\",OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer_ordinal = Pipeline(\n",
    "    step = [\n",
    "        (\"ordinal_encoder\",OrdinalEncoder(handel_unknown = \"use_encoded_value\",unknown_value=-1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Formation Normal\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_trans\",numerical_transformer,num_cols),\n",
    "        (\"cat_trans_oht\",categorical_transformer_oht,oht_encoder),\n",
    "        (\"cat_trans_ord\",categorical_transformer_ordinal,o_encoder)\n",
    "])\n",
    "\n",
    "# Formation two ref:https://contrib.scikit-learn.org/category_encoders/targetencoder.html\n",
    "from category_encoders.target_encoder import TargetEncoder \n",
    "column_trans = make_column_transformer(\n",
    "    (TargetEncoder(handle_unknown='ignore'),oht_encoder ), #2\n",
    "    remainder='passthrough')\n",
    "\n",
    "# Formation three special\n",
    "# ref:https://colab.research.google.com/drive/1-H8ZfuemZAW_imWCVJPj_syfrZOnPAyT?usp=sharing\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "cat_features_idx = [df.columns.get_loc(col) for col in cat_cols]\n",
    "column_trans = make_column_transformer(\n",
    "    (SMOTENC(cat_features_idx),feature_cols), # 1\n",
    "    (PCA(n_components=2),num_corr_features ), # 1\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier(scale_pos_weight=class_weight,seed=42)\n",
    "model = RandomForestClassifier(n_estimators=300,class_weight= {0:1,1:class_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(step=[\n",
    "    (\"preprocess\",preprocess),\n",
    "    (\"model\",model)\n",
    "    ]\n",
    ")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing to Baseline model\n",
    "metric_calculator(y_test,np.zeros_like(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "cross_val_score(pipe,x_train, x_test, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "# Custom train \n",
    "model, y_pred, y_prob = train_model(pipe,x_train, x_test, y_train.values.flatten(), y_test.values.flatten())\n",
    "metric_calculator(y_test,y_pred,y_prob,y_prob_flag=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_names = list(model.named_steps['preprocess'].named_transformed['numerical_trans'].named_steps['imputer'].feature_names_in_)\n",
    "\n",
    "cat_oht_cols = list(model.named_step['preprocess'].named_transfomer['cat_trans_oht'].named_steps['oht_encoder'].get_feature_names_out(input_features=oht_encoder))\n",
    "\n",
    "cat_ord_cols = list(model.named_step['preprocess'].named_transfomer['cat_trans_ord'].named_steps['ordinal_encoder'].get_feature_names_out(input_features=o_encoder))\n",
    "\n",
    "feature_imp_names = feature_imp_names + cat_oht_cols + cat_ord_cols\n",
    "coefs = pipe.named_steps['classifier'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check \n",
    "if feature_imp_names.__len__() == pipe.named_steps['classifier'].n_features_in_:\n",
    "    print(\"Input and output feature match in pipeline\")\n",
    "else:\n",
    "    print(\"COUNT DOES NOT MATCH: with input and output feature in pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip coefficients and names together and make a DataFrame\n",
    "zipped = zip(features_imp_names, coefs)\n",
    "\n",
    "df = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "\n",
    "# Sort the features by the absolute value of their coefficient\n",
    "\n",
    "df[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "\n",
    "df[\"colors\"] = df[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "\n",
    "df = df.sort_values(\"abs_value\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"value\",\n",
    "            data=df.head(20),\n",
    "           palette=df.head(20)[\"colors\"])\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n",
    "ax.set_title(\"Top 20 Features\", fontsize=25)\n",
    "ax.set_ylabel(\"Feature Importance/Coef\", fontsize=22)\n",
    "ax.set_xlabel(\"Feature Name\", fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "eli5.explain_weights(model.named_steps['classifier'], top=50, feature_names=features_imp_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model training and submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "model_holder = {}\n",
    "for i, (train_index, test_index) in enumerate(skf.split(x, y)):\n",
    "    x_tr = x.loc[train_index]\n",
    "    y_tr = y.loc[train_index]\n",
    "    \n",
    "    x_val = x.loc[test_index]\n",
    "    y_val = y.loc[test_index]\n",
    "\n",
    "    model, y_pred, y_prob = train_model(pipe,x_train, x_test, y_train, y_test)\n",
    "\n",
    "    model_holder[i] = model\n",
    "\n",
    "    print(f\"======= Fold {i} ========\")\n",
    "    metric_calculator(y_test,y_pred,y_prob)\n",
    "print(\"All models training is done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blending\n",
    "Each model is train on various parameters so we performs the blending on of each model prediction to create final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for idx, model in enumerate(model_holder):\n",
    "    result[idx]=model.predict_proba(y_test)[1]\n",
    "\n",
    "res_df = pd.DataFrame(data=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['Weighted_Avg']=(5*res_df['1']+2*res_df['2']+\n",
    "                      3*(res_df['3']))/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ans=pd.read_csv(\"/job_a_thon/dataset/sample_submission_QrCyCoT.csv\")\n",
    "final_ans.to_csv(\"/job_a_thon/dataset/sample_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "final_ans = pd.DataFrame()\n",
    "\n",
    "final_ans[\"Response\"] =  df['Weighted_Avg']\n",
    "final_ans[\"Response\"] = [1 if x > 0.5 else 0 for x in res_df['Weighted_Avg']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:13:39) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27fdf8b55b6c16a381e9a7767be7eee3cba98b8b0a56aef2784cde6e6d4b61b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
